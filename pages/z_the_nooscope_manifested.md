---
title: The Nooscope Manifested
---

- language
:PROPERTIES:
:todo: 1615665345439
:END:

parameters and hyperparameters
: The parameters of a model that are learnt from data are called ‘parameters’, while parameters that are not learnt from data and are fixed manually are called ‘hyperparameters’ (These determine number and properties of the parameters).

overfitting
: to learn everything (including noise) and is not able to distinguish a pattern from its background

underfitting
: not able to detect meaningful patterns from the training data

interpolation
: the prediction of an output y within the known interval of the input x in the training dataset

extrapolation
: the prediction of output y beyond the limits of x, often with high risks of inaccuracy

training dataset
: the system under observation

learning algorithm
: the instrument of observation

statistical model
: the ossification of that which is learned

machine learning
: the assemblage of training dataset, statistical model, and learning algo

Biases
- **Historical Bias** (or world bias) is already apparent in society before technological intervention
- **Dataset Bias** is introduced through the preparation of training data by human operators
- **Algorithmic bias** (also known as machine bias, statistical bias or model bias) is the further amplification of historical bias and dataset bias by machine learning algorithms, mostly caused by information compression, which engenders issues of information resolution, diffraction and loss
- the optical instrument acted as knowledge magnification insofar as it expanded the realm of digestible data; [thence, equivalence classes].
  - 
> Optical lenses symbolize biases and approximations representing the compression and distortion of the information flow. The total bias of machine learning is represented by the central lens of the statistical model through which the perception of the world is diffracted
  - 
> The limitations of AI are generally perceived today thanks to the discourse on bias —the amplification of gender, race, ability, and class discrimination by algorithms
- 
> In the same way that the lenses of microscopes and telescopes are never perfectly curvilinear and smooth, the logical lenses of machine learning embody faults and biases. To understand machine learning ... is to study the degree by which social data are diffracted and distorted by these lenses.
-
  - 
> When Greta Thunberg warns ‘Listen to science.’ what she really means, being a good student of mathematics, is ‘Listen to the statistical models of climate science.’
- the statistical model is a means by which representations of the world can be created. just as a lens can be moved about to represent different worlds in different eyes, the model may be used to represent any input.
- 
> The arms race of AI companies is, still today, concerned with finding the simplest and fastest algorithms with which to capitalise data. If [[information compression]] produces the maximum rate of profit in corporate AI, from the societal point of view, it produces discrimination and the loss of cultural diversity.
- 
> ImageNet is a training dataset for Deep Learning that has become the de facto benchmark for image recognition algorithms ... anonymous workers from all over the planet were paid few cents per task to label hundreds of pictures per minute according to the WordNet taxonomy ... see the legitimation of the category ‘failure, loser, nonstarter, unsuccessful person’ for a hundred arbitrary pictures of people
-
> Head of Facebook AI and godfather of convolutional neural networks Yann LeCun reiterates that current AI systems are not sophisticated versions of cognition, but rather, of perception
- 
> As an instrument of knowledge, machine learning is composed of an object to be observed (training dataset), an instrument of observation (learning algorithm) and a final representation (statistical model). The assemblage of these three elements is proposed here as a spurious and baroque diagram of machine learning, extravagantly termed Nooscope.

> For explanatory purposes, the Nooscope is described as a machine that operates on three modalities: training, classification, and prediction. In more intuitive terms, these modalities can be called: pattern extraction, pattern recognition, and pattern generation ... What a neural network computes, is not an exact pattern but the statistical distribution of a pattern. Just scraping the surface of the anthropomorphic marketing of AI, one finds another technical and cultural object that needs examination: the statistical model ... In terms of the work of demystification that needs to be done (also to evaporate some naïve questions), it would be good to reformulate the trite question ‘Can a machine think?’ into the theoretically sounder questions ‘Can a statistical model think?’, ‘Can a statistical model develop consciousness?’, et cetera.
  -
> Classification is known as pattern recognition, while prediction can be defined also as pattern generation ... A self-driving vehicle is trained to recognise different objects on the road ... and predict future actions based on decisions that a human driver has taken
  -
> In this [the generative] modality, the neural network is run backwards ... to generate new patterns after being trained at classifying them
    - 
> In DeepDream first experiments, bird feathers and dog eyes started to emerge everywhere as dog breeds and bird species are vastly overrepresented in ImageNet. It was also discovered that the category ‘dumbbell’ was learnt with a surreal human arm always attached to it.
  - 
> Algorithm is the name of a process, whereby a machine performs a calculation. The product of such machine processes is a statistical model ... In the developer community, the term ‘algorithm’ is increasingly replaced with ‘model.’ ... This terminological confusion arises from the fact that the statistical model does not exist separately from the algorithm: somehow, the statistical model exists inside the algorithm under the form of distributed memory across its parameters ... The algorithm starts as a blank slate and, during the process called training, or ‘learning from data', adjusts its parameters until it reaches a good representation of the input data
  -
> A statistical model is said to be trained successfully when it can elegantly fit only the important patterns of the training data
  - 
> machine learning simply maps a statistical distribution of numerical values and draws a mathematical function that hopefully approximates human comprehension
- 
> the performance of ‘machine intelligence’ in this case can be measured also by the proportion between the size of training data and the trained algorithm (or model). ImageNet contains 14 million images with associated labels that occupy approximately 150 gigabytes of memory. On the other hand, Inception v3, which is meant to represent the information contained in ImageNet, is only 92 megabytes. The ratio of compression between training data and model partially describes also the rate of information diffraction
- 
> AI is a heavily compressed and distorted map ... without community access and community consent ... there is never territory per se, but always an act of territorialisation.
-
> A neural network requires the inputs of the calculator to take on the form of a vector. Therefore, the world must be coded in advance in the form of a purely digital vectorial representation ... To input a word into a neural network, the Word2vec technique ‘embeds’ it into a vectorial space that measures its distance from the other words in the corpus ... Two terms whose inferred positions are near one another in this space are equally similar semantically; these representations are said to be distributed: the vector of the concept ‘apartment’ ... will be similar to that of ‘house’ ...
  -
> William Gibson’s original definition of cyberspace prophesized, most likely, the coming of a vector space rather than virtual reality: ‘A graphic representation of data abstracted from the banks of every computer in the human system. Unthinkable complexity. Lines of light ranged in the nonspace of the mind, clusters and constellations of data. Like city lights, receding.’
  - 
> one trick of [[information compression]] is **dimensionality reduction**, which is used to avoid ... the exponential growth of the variety of features in the vector space ... categories that show low variance in the vector space ... are aggregated to reduce calculation costs ... but can also lead to **category reduction**, which can have an impact on the representation of social diversity
- even if all the algorhithms are open sourced, nobody can read them; even if the datasets are open sourced, nobody can get the electricity to process them; openness is necessary for epistemic justice, but sufficiency is a cybernetic endeavor.
-
> the inability to recognise a **unique anomaly** that appears for the first time, such as ... an unusual obstacle (a pedestrian? a plastic bag?) on the road scenario. The **undetection of the new** (something that has never ‘been seen’ by a model and therefore never classified before in a known category) ... has already caused fatalities ... machine learning automates the dictatorship of the past ... termed the **regeneration of the old** ... the application of a homogenous space-time view that restrains the possibility of a new historical event
  - [[the end of history]]
  - creativity as the reconfiguration of the old into the novel; what aspects of novelty does this regime crush, and what paths does it open?
-
> The problems characteristic of the prediction of the new are logically related to those that characterise the generation of the new, because the way a machine learning algorithm predicts a trend on a time chart is identical to the way it generates a new artwork from learnt patterns ... ‘Can AI be creative?’ should be reformulated in technical terms: Is machine learning able to extrapolate beyond the stylistic boundaries of its training data? ... The ‘creativity’ of machine learning is limited to the detection of styles from the training data and then random improvisation within these styles ... it would be more accurate to term machine learning art as statistical art
-
> Rather than studying only how technology works, critical inquiry studies also how it breaks, how subjects rebel against its normative control and workers sabotage its gears. In this sense, a way to sound the limits of AI is to look at hacking practices
- AI, as a generally rule, outsources what we might call knowledge work to labelers in the third world
- 
> The information flow of AI ... extract[s] ‘analytical intelligence’ from the most diverse forms of labour and ... ***transfer***[s] such intelligence into a machine
- 
> a paper from the European Trade Union Institute, which highlights ‘seven essential dimensions that future regulation should address in order to protect workers: 1) safeguarding worker privacy and data protection; 2) addressing surveillance, tracking and monitoring; 3) making the purpose of AI algorithms transparent; 4) ensuring the exercise of the ‘right to explanation’ regarding decisions made by algorithms or machine learning models; 5) preserving the security and safety of workers in human-machine interactions; 6) boosting workers’ autonomy in human–machine interactions; 7) enabling workers to become AI literate
- 
> The Machinery Question was a debate that sparked in England during the industrial revolution, when the response to the employment of machines and workers’ subsequent technological unemployment was a social campaign for more education about machines, that took the form of the Mechanics’ Institute Movement
